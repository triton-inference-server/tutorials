# Client Inference Generators

The files in this folder are for the deployment of client pods in the same cluster as a model hosted by Triton + TRT-LLM using
the provided sample Helm chart.
Each file creates a single deployment of a client container which can be used to generate inference requests for the deployed
model.
